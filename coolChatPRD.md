# ðŸ“˜ Product Requirements Document (PRD) for **coolChat**

## 1. Vision & Goals

coolChat is a lightweight, Python-based LLM client inspired by **SillyTavern**, but optimized for:

* **Lower memory usage** (Python backend + efficient front-end).
* **Extensibility via plugins** (tools, backgrounds, integrations).
* **Cross-platform usability** (desktop, web-first design).
* **User focus**: Chat roleplay, productivity, tool integration, modularity.

---

## 2. Current State (as observed)

* **Architecture**:

  * Python backend (FastAPI/Flask style endpoints).
  * Frontend folder (likely HTML/JS UI).
  * Plugins system started (animated backgrounds, tool calls).
* **Features implemented**:

  * Chat interface with LLM backends.
  * Basic plugin loader.
  * Tool calling endpoint exists but **not functioning reliably**.
* **Gaps vs. SillyTavern**:

  * No world info / memory persistence.
  * Limited character card support.
  * Incomplete tool invocation and chaining.
  * Missing RAG integration, multi-chat rooms, or group bots.

---

## 3. Key Issues & Bugs

1. **Tool calling not working**

   * Current `/tools` route does not properly execute tool functions or return responses in expected schema.
   * Likely issue: inconsistent JSON schema (`toolCalls` vs. `tool_calls`), or async handling failures.
   * Needs a retry-safe, schema-validated handler.

2. **Plugin architecture is skeletal**

   * Animated background works, but no plugin manager / hot reload.
   * Risk of plugin breakage on update.

3. **UI/UX**

   * Frontend is very minimal; lacks session management, character creation, and persistent history.

---

## 4. Feature Requirements (Parity with SillyTavern)

### Core Features

* âœ… **Chat with LLMs** (OpenAI, local backends, API endpoints).
* âœ… **Character cards** (import/export JSON, PNG-embedded metadata).
* ðŸ”² **World Info / Lorebooks**: structured knowledge injection.
* ðŸ”² **Group chats**: multiple bots + user.
* ðŸ”² **Session management**: save/load conversations.
* ðŸ”² **Memory persistence**: long-term context caching.

### Tooling

* ðŸ”² **Tool calling** (robust implementation with schema validation).
* ðŸ”² **Plugins framework** (hot-load, enable/disable).
* ðŸ”² **RAG integration** (local embeddings + vector DB for memory).

### Media Features

* ðŸ”² **TTS/STT integration** (whisper, Coqui, or external APIs).
* ðŸ”² **Image gen APIs** (Pollinations, Dezgo, NanoGPT, or external APIs).
   - User customizable external APIs. User's should be able to provide a JSON file that will be read by the app to configure any customer API image generation provider. Many providers use different API schemas so different settings will need configured for each API. Feel free to use DEZGO and pollinations as examples. Create the config JSON files for those two providers based on how they are currently coded.
* ðŸ”² **Background customization** This should be accomplished through plugins exclusively.  The native app should just have a basic background color from the theme. But the backgroundAnimations plugin should add the layered background animations we've been workign on. Future plugins could enable background images generated by the AI, videos, music visualizers, etc.

### Performance

* ~~ðŸ”² **Streaming responses** (token-by-token).~~ streaming is not necessary for the initial release of the app. I feel it will add too much complexity at this time.
* ðŸ”² **Low-memory mode** (offload context to disk).
* ðŸ”² **Smart Context Management** Use multiple strategies to manage large context chats. Utilize RAG, lorebooks and/or other methods to be as token efficient as possible while retaining all the important chat context.
* ðŸ”² **Async concurrency** for tool calls + LLM responses.
   - This needs to be toggleable though as some users and LLM APIs may not allow for multiple calls at once.

---

## 5. Roadmap / Phases

### **Phase 1: Stabilization (Weeks 1â€“2)**

* Fix **tool calling** endpoint:

  * Standardize schema (`name`, `arguments`, `id`).
  * Add logging for failures.
  * Unit test with mock tools.
* Add **persistent conversation storage** (SQLite or JSON).
* Document plugin API clearly.

### **Phase 2: Feature Parity MVP (Weeks 3â€“5)**

* Implement **character card import/export**.
* Add **World Info / lorebook injection**.
* Support **multi-chat / group bots**.
* Add streaming responses.

### **Phase 3: Expansion (Weeks 6â€“8)**

* **Plugin manager** with UI toggle.
* **RAG memory** via sentence-transformers + FAISS/Chroma.
* **Image gen + TTS** hooks.

### **Phase 4: Polish (Weeks 9â€“12)**

* Improved UI (React or lightweight Vue).
* Themes + animated backgrounds.
* Performance testing: optimize memory footprint.
* Documentation: usage, API, dev guide.

---

## 6. Technical Requirements

* **Backend**: Python (FastAPI preferred for async).
* **Frontend**: Vanilla JS (upgradeable to React).
* **Storage**: SQLite (lightweight, portable).
* **Embeddings**: sentence-transformers (all-MiniLM-L6-v2).
* **Plugins**: JSON manifest + Python/JS handlers.

---

## 7. Acceptance Criteria

* Tool calling works with at least 3 sample tools (math, search, local file lookup).
* Character cards can be imported/exported and used in conversation.
* Lorebook injects text when keywords triggered.
* Conversations persist across reload.
* Plugins can be enabled/disabled without code edits.

---

## 8. Risks & Mitigation

* **Memory creep**: mitigate by offloading context to disk + streaming.
* **Plugin instability**: enforce schema validation.
* **Frontend sprawl**: keep UI minimal first, expand later.

---

âš¡ **Next Step Recommendation**:
Start by **fixing tool calling** and adding **persistent conversation storage**. These give immediate usability wins and unlock the rest of the roadmap.

---

